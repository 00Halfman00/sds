{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e9a75ce",
   "metadata": {},
   "source": [
    "# Welcome to Week 3!\n",
    "\n",
    "## Agenda\n",
    "\n",
    "### Part 1: Intro\n",
    "\n",
    "1. A review of your own [Evals](https://docs.google.com/presentation/d/1OI-9yqJWK5hHNO06JDz44UduN4YmTf1HP-IRTtuAnig/edit?slide=id.p10#slide=id.p10)\n",
    "2. What is an Agent?\n",
    "3. Digital Twin Teams\n",
    "4. First Agent labs - structured outputs (lab 2)\n",
    "\n",
    "### Part 2: Agents\n",
    "\n",
    "- Streaming (lab 3)\n",
    "- Tools (lab 4)\n",
    "- Interactions (lab 5)\n",
    "- Coding (lab 6)\n",
    "- Agent Loop (lab 7)\n",
    "\n",
    "### Part 3: Team planning\n",
    "\n",
    "1. Group and plan\n",
    "2. Experiment!\n",
    "3. Determine approach\n",
    "4. Regroup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1b2670",
   "metadata": {},
   "source": [
    "## New Teams for Digital Twin\n",
    "\n",
    "The idea is that each of you builds the Digital Twin individually, but you collaborate to share your approach and leanings together, and to share tools.\n",
    "\n",
    "**Team 1:**\n",
    "\n",
    "Seb, Kinjal, Marylou, Dave\n",
    "\n",
    "**Team 2:**\n",
    "\n",
    "Jeff, Rohit, Salma\n",
    "\n",
    "**Team 3:**\n",
    "\n",
    "Sathiya, Ilya, Oscar, Josh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9921dedb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from agents import Agent, Runner\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20736ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: What does an agentic AI do after finishing a task?\n",
      "A: It writes its own performance review and gives itself a raise.\n"
     ]
    }
   ],
   "source": [
    "# Create an Agent instance named \"Jokester\" that uses the GPT-5 Nano model.\n",
    "# Agents are LLM wrappers with additional behavior — they can have memory, tools, and goals.\n",
    "agent = Agent(name=\"Jokester\", model=\"gpt-5-nano\")\n",
    "\n",
    "# Use the Runner class to asynchronously execute a task with the agent.\n",
    "# Runner.run(...) handles the conversation loop — it sends the user's message to the agent,\n",
    "# waits for a response, and manages things like streaming or intermediate steps if the agent uses tools.\n",
    "response = await Runner.run(agent, \"Tell me a joke about Agentic AI\")\n",
    "\n",
    "# Print the agent’s final generated output (the actual answer text).\n",
    "# The response object may also include structured metadata such as reasoning traces or tool usage logs.\n",
    "print(response.final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0aa163",
   "metadata": {},
   "source": [
    "## 🧠 In short:\n",
    "Agent → defines who is speaking (its model, personality, and abilities).\n",
    "\n",
    "Runner.run() → defines how the interaction happens (runs the agent with your prompt).\n",
    "\n",
    "await → because the LLM call is asynchronous — it may stream or wait for a response.\n",
    "\n",
    "response.final_output → the final message after any internal reasoning or tool use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "072ab6a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n┌──────────────────────────────────────────────────────────────────┐\\n│                          YOUR NOTEBOOK                           │\\n└──────────────────────────────────────────────────────────────────┘\\n                 │\\n                 │ 1️⃣ You create an Agent\\n                 ▼\\n        ┌─────────────────────────────┐\\n        │ Agent(name=\"Jokester\",      │\\n        │       model=\"gpt-5-nano\")   │\\n        └─────────────────────────────┘\\n                 │\\n                 │ 2️⃣ You tell the Runner to \"run\" that agent\\n                 ▼\\n        ┌─────────────────────────────┐\\n        │ Runner.run(agent,           │\\n        │   \"Tell me a joke about     │\\n        │    Agentic AI\")             │\\n        └─────────────────────────────┘\\n                 │\\n                 │ 3️⃣ Runner sets up async execution\\n                 │    (e.g., event loop, streaming, logging)\\n                 ▼\\n        ┌─────────────────────────────┐\\n        │ Agent receives user input   │\\n        │ and sends it to model API   │\\n        └─────────────────────────────┘\\n                 │\\n                 │ 4️⃣ Model processes request\\n                 ▼\\n        ┌─────────────────────────────┐\\n        │ gpt-5-nano model generates  │\\n        │ a humorous response          │\\n        └─────────────────────────────┘\\n                 │\\n                 │ 5️⃣ Agent wraps model output\\n                 │     into a structured Response\\n                 ▼\\n        ┌─────────────────────────────┐\\n        │ response = {                │\\n        │   final_output: \"Here’s a   │\\n        │     joke about Agentic AI…\" │\\n        │   metadata: {...}           │\\n        │ }                           │\\n        └─────────────────────────────┘\\n                 │\\n                 │ 6️⃣ You print the joke\\n                 ▼\\n        ┌─────────────────────────────┐\\n        │ print(response.final_output)│\\n        └─────────────────────────────┘\\n                 │\\n                 ▼\\n           🧠 The agent replies\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "┌──────────────────────────────────────────────────────────────────┐\n",
    "│                          YOUR NOTEBOOK                           │\n",
    "└──────────────────────────────────────────────────────────────────┘\n",
    "                 │\n",
    "                 │ 1️⃣ You create an Agent\n",
    "                 ▼\n",
    "        ┌─────────────────────────────┐\n",
    "        │ Agent(name=\"Jokester\",      │\n",
    "        │       model=\"gpt-5-nano\")   │\n",
    "        └─────────────────────────────┘\n",
    "                 │\n",
    "                 │ 2️⃣ You tell the Runner to \"run\" that agent\n",
    "                 ▼\n",
    "        ┌─────────────────────────────┐\n",
    "        │ Runner.run(agent,           │\n",
    "        │   \"Tell me a joke about     │\n",
    "        │    Agentic AI\")             │\n",
    "        └─────────────────────────────┘\n",
    "                 │\n",
    "                 │ 3️⃣ Runner sets up async execution\n",
    "                 │    (e.g., event loop, streaming, logging)\n",
    "                 ▼\n",
    "        ┌─────────────────────────────┐\n",
    "        │ Agent receives user input   │\n",
    "        │ and sends it to model API   │\n",
    "        └─────────────────────────────┘\n",
    "                 │\n",
    "                 │ 4️⃣ Model processes request\n",
    "                 ▼\n",
    "        ┌─────────────────────────────┐\n",
    "        │ gpt-5-nano model generates  │\n",
    "        │ a humorous response          │\n",
    "        └─────────────────────────────┘\n",
    "                 │\n",
    "                 │ 5️⃣ Agent wraps model output\n",
    "                 │     into a structured Response\n",
    "                 ▼\n",
    "        ┌─────────────────────────────┐\n",
    "        │ response = {                │\n",
    "        │   final_output: \"Here’s a   │\n",
    "        │     joke about Agentic AI…\" │\n",
    "        │   metadata: {...}           │\n",
    "        │ }                           │\n",
    "        └─────────────────────────────┘\n",
    "                 │\n",
    "                 │ 6️⃣ You print the joke\n",
    "                 ▼\n",
    "        ┌─────────────────────────────┐\n",
    "        │ print(response.final_output)│\n",
    "        └─────────────────────────────┘\n",
    "                 │\n",
    "                 ▼\n",
    "           🧠 The agent replies\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a0c799",
   "metadata": {},
   "source": [
    "🕹️ 3️⃣ Architecture overview\n",
    "\n",
    "Here’s the mental model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae22bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "           ┌────────────────────┐\n",
    "           │   Runner (Orchestrator) │\n",
    "           └──────────┬───────────┘\n",
    "                      │\n",
    "                      ▼\n",
    "             ┌─────────────────┐\n",
    "             │   Agent Object  │  ← Your “Jokester”\n",
    "             │ - model: gpt-5-nano\n",
    "             │ - tools: (none, or optional)\n",
    "             │ - memory, goals, etc.\n",
    "             └─────────────────┘\n",
    "                      │\n",
    "                      ▼\n",
    "             ┌─────────────────┐\n",
    "             │   LLM backend   │  ← The actual GPT model\n",
    "             └─────────────────┘\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
