{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5724b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Agent, Runner, trace\n",
    "from IPython.display import Markdown, display\n",
    "from pydantic import BaseModel, Field\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e55c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "entrepreneur_instructions = \"You generate novel, exciting business ideas for Autonomous AI Agents\"\n",
    "entrepreneur_input = \"\"\"\n",
    "Propose one compelling business idea for applying Autonomous AI Agents to any industry you choose.\n",
    "The idea should be unique, high potential commercial impact, and make true use of the autonomous capabilities of AI Agents.\n",
    "\"\"\"\n",
    "\n",
    "evaluator_instructions = \"You evaluate novel, exciting business ideas for Autonomous AI Agents\"\n",
    "evaluator_input = \"Evaluate the following business idea; assess it for uniqueness, potential commercial impact, and use of Autonomous AI Agents:\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143b0145",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Idea(BaseModel):\n",
    "    title: str = Field(description=\"The title of the idea\")\n",
    "    description: str = Field(description=\"A detailed description of the idea, in Markdown\")\n",
    "\n",
    "    def print_summary(self):\n",
    "        print(f\"Title: {self.title}\")\n",
    "        display(Markdown(self.description))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79decdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluation(BaseModel):\n",
    "    idea: Idea = Field(description=\"The idea that you are evaluating\")\n",
    "\n",
    "    uniqueness_feedback: str = Field(description=\"Your view on how unique the idea is\")\n",
    "    uniqueness_score: int = Field(description=\"How unique the idea is, on a scale of 1 to 10, where 1 is mundane and 10 is groundbreaking\")\n",
    "\n",
    "    commercial_feedback: str = Field(description=\"Your view on the commercial potential of the idea\")\n",
    "    commercial_score: int = Field(description=\"How high the commercial potential of the idea is from 1 to 10, where 1 is barely profitable and 10 is a billion dollar idea\")\n",
    "\n",
    "    autonomy_feedback: str = Field(description=\"Your commentary on to what extent the idea truly benefits from the autonomous nature of AI Agents\")\n",
    "    autonomy_score: int = Field(description=\"How deeply the idea involves autonomous agents from 1 to 10, where 1 is that it plays no meaningful role, and 10 is that it is pivotal\")\n",
    "\n",
    "    def is_brilliant(self):\n",
    "        return self.uniqueness_score > 8 and self.commercial_score > 8 and self.autonomy_score > 8\n",
    "\n",
    "    def print_summary(self):\n",
    "        print(f\"Idea: {self.idea.title}\")\n",
    "        print(f\"Uniqueness: {self.uniqueness_score}/10: ({self.uniqueness_feedback})\")\n",
    "        print(f\"Commercial: {self.commercial_score}/10: ({self.commercial_feedback})\")\n",
    "        print(f\"Autonomy: {self.autonomy_score}/10: ({self.autonomy_feedback})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022321cf",
   "metadata": {},
   "source": [
    "## Approach 1 (Highly Recommended!) - Call Runner.run() separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86de517",
   "metadata": {},
   "outputs": [],
   "source": [
    "entrepreneur = Agent(name=\"Entrepreneur\", model=\"gpt-4.1-mini\", instructions=entrepreneur_instructions, output_type=Idea)\n",
    "result = await Runner.run(entrepreneur, entrepreneur_input)\n",
    "idea = result.final_output_as(Idea)\n",
    "idea.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99eb219c",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Agent(name=\"Evaluator\", model=\"gpt-4.1-mini\", instructions=evaluator_instructions, output_type=Evaluation)\n",
    "result = await Runner.run(evaluator, f\"{evaluator_input}{idea}\")\n",
    "evaluation = result.final_output_as(Evaluation)\n",
    "evaluation.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f63c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "entrepreneur_latest = f\"You were originally given the following task:\\n\\n{entrepreneur_input}\\n\\n\"\n",
    "remaining_attempts = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ef6421",
   "metadata": {},
   "outputs": [],
   "source": [
    "with trace(\"Entrepreneur Approach 1\"):\n",
    "    while not evaluation.is_brilliant() and remaining_attempts:\n",
    "        remaining_attempts -= 1\n",
    "\n",
    "        # Build a composite prompt that includes:\n",
    "        # - The original task\n",
    "        # - The last idea and feedback\n",
    "        # - Instructions to improve the idea\n",
    "        entrepreneur_latest += (\n",
    "            f\"You responded with this idea:\\n\\n{idea}\\n\\n\"\n",
    "            f\"You received this feedback:\\n\\n{evaluation}\\n\\n\"\n",
    "            \"Now respond with an improved idea that addresses the feedback. \"\n",
    "            \"Do not directly reference the feedback.\\n\\n\"\n",
    "        )\n",
    "\n",
    "        # ðŸ”¹ Step 1: Entrepreneur proposes an improved idea\n",
    "        result = await Runner.run(entrepreneur, entrepreneur_latest)\n",
    "        idea = result.final_output_as(Idea)\n",
    "        idea.print_summary()\n",
    "\n",
    "        # ðŸ”¹ Step 2: Evaluator evaluates the new idea\n",
    "        result = await Runner.run(evaluator, f\"{evaluator_input}{idea}\")\n",
    "        evaluation = result.final_output_as(Evaluation)\n",
    "        evaluation.print_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d335780",
   "metadata": {},
   "source": [
    "## ðŸ§  Key Things to Notice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a38b61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Element\t                    Purpose\n",
    "Agent(...)\t                Defines a role and behavior (Entrepreneur or Evaluator). Each is an LLM with a specific set of instructions.\n",
    "Runner.run(agent, input)\t  Executes one turn for the agent â€” sending the input and collecting the structured result.\n",
    "Idea / Evaluation\t          Typed outputs using Pydantic models, so you can programmatically access structured fields (idea.title, evaluation.commercial_score, etc.).\n",
    "evaluation.is_brilliant()\t  Simple logic gate to determine when to stop iterating.\n",
    "with trace(\"...\"):\t        Creates a trace span that groups all of these interactions together for analysis, logging, or visualization.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc416711",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
